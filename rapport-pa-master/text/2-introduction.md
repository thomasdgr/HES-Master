\pagenumbering{arabic}

# Introduction {-}

L'avènement de ChatGPT vers la fin de l'année 2022 a marqué une véritable révolution dans l'utilisation des systèmes d' (+IA_a) générative. Cette dernière s'est manifestée par la mise en œuvre quasi instantanée des (+LLM_a) chez les géants Meta (Facebook), Google, Microsoft, etc. À l'aube d'une immense vague d'innovation, il n'a jamais été aussi facile d'utiliser ces outils qui ont bouleversé nos quotidiens. Si OpenAI a déclenché cet enthousiasme grandissant, ces modèles reposent en réalité sur une architecture de réseaux neuronaux conceptualisée il y a plusieurs années par Google : les Transformers.

Combinés avec des techniques d'entraînement avancées et une quantité de données colossale, les Transformers font des (+LLM_a), de puissants assistants capables de générer et traduire du texte, de rédiger du code ou encore de répondre à des questions dans une multitude de langues. Le très célèbre rapport "Data Age 2025", réalisé par l'International Data Corporation, précise que la quantité de données générées en 2025 est évaluée à 163 zettabits contre 33 en 2018. Cette croissance exponentielle des données disponibles est un des facteurs clés du succès de ces modèles, mais soulève toutefois des questions sur leur obsolescence. Les coûts faramineux liés à l'entraînement, à la consommation énergétique et à la qualité des réponses sont tout autant de limites technologiques qui se posent. Dans un contexte où même les (+LLM_a) ne sont pas des outils miracles, l'idée des (+RAG_a) Systems émerge pour les améliorer.

Ce projet réalisé dans le cadre du master MSE de la HES-SO vise à étudier en détail le fonctionnement de ces technologies afin de répondre à plusieurs questions ouvertes. Une étude menée en 2024 par Florence Meyer, responsable du service académique à la (+HEIAFR_a), sur la facilité d'accès aux informations administratives pour les étudiants, a fait émerger le besoin d'un assistant virtuel dans le but de centraliser les sources d'informations en ligne jugées trop éparses. La mise en place de ce use-case aidera aussi à identifier dans quelle mesure les (+RAG_a) peuvent aider à concevoir des systèmes d' (+IA_a) personnalisés et adaptés à des besoins spécifiques.

L’intégralité du code et des données utilisées sont disponibles sur le repo[^1] de ce projet.

\pagebreak

[^1]: Disponible à l'adresse: \url{https://gitlab.forge.hefr.ch/thomas.dagierjo/pa-chatbot}