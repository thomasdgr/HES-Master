{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold-out validation\n",
    "In hold-out validation the dataset is split in two parts: one part is used during training and the other is used for testing the generalization capabilities of the model. This method has the advantage of being easy to implement. However, in hold-out validation the generalisation performance is evaluated with a single test, using a dataset partition that not necessarily represents the whole distribution of the whole dataset. Hence, it can produce some undesirable behaviours that lead to a wrong assessment of the performance of the model. In this notebook you are going to explore the behaviour of hold-out validation by simulating datasets with diverse degrees of complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import sys\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "This function creates a dataset with two classes in two dimensions. It has two parameters: the size of the dataset and the spread of each one of the classes. A high spread value makes both classes to superpose, making the classification more difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(n, s):\n",
    "    n1 = int(np.ceil(n / 2.0))\n",
    "    n2 = int(np.floor(n / 2.0))\n",
    "    x1 = np.random.normal(-1, s, n1)\n",
    "    y1 = np.random.uniform(-1, 1,  n1)\n",
    "    x2 = np.random.normal(1, s, n2)\n",
    "    y2 = np.random.uniform(-1, 1, n2)\n",
    "    return np.stack((np.concatenate((x1, x2)), np.concatenate((y1, y2)), np.concatenate((np.ones(n1), -1*np.ones(n2)))), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(s):\n",
    "    dataset = create_dataset(200, s)\n",
    "    pl.scatter(dataset[:,0], dataset[:,1], c=[(['b', 'r'])[int(cl > 0)] for cl in dataset[:,2]])\n",
    "    pl.xlim(-3,3)\n",
    "    pl.ylim(-1,1)\n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b3190c61f741379593968eb3684d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='Spread:', max=1.0, min=0.1, step=0.01), Output()), _â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plot_dataset, s=widgets.FloatSlider(value=0.1, min=0.1, max=1.0, step=0.01, description='Spread:',));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlp_backprop_momentum as mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring hold-out validation\n",
    "The following function splits the dataset in two parts. The parameter `train_test_ratio` controls the proportions of the partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_test_ratio = 0.8):\n",
    "    index_all = np.arange(dataset.shape[0])\n",
    "    np.random.shuffle(index_all)\n",
    "    break_point = int(train_test_ratio * len(index_all))\n",
    "    index_train = index_all[0:break_point]\n",
    "    index_test = index_all[break_point:]\n",
    "    dataset_train = dataset[index_train,:]\n",
    "    dataset_test = dataset[index_test,:]\n",
    "    return (dataset_train, dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "In this experiment we create datasets with different degrees of complexity and we test the behaviour of hold-out validation with each one of them. For each dataset, we split the dataset several times, which generates different partitions training/testing. We also initializes the neural networks several times with each partition in order to be sure that the results are not a special case of a lucky initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INITS = 2\n",
    "N_SPLITS = 10\n",
    "DATASET_SIZE = 200\n",
    "EPOCHS = 100\n",
    "N_NEURONS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.7\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "DATA_PARAMS = np.arange(0.4, 0.71, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset with variance: 0.4\n",
      "."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (3,1) doesn't match the broadcast shape (3,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         output_data_test \u001b[39m=\u001b[39m dataset_test[:,nn\u001b[39m.\u001b[39mn_inputs:(nn\u001b[39m.\u001b[39mn_inputs\u001b[39m+\u001b[39mnn\u001b[39m.\u001b[39mn_outputs)]\n\u001b[1;32m     20\u001b[0m         t \u001b[39m=\u001b[39m (d \u001b[39m*\u001b[39m N_INITS) \u001b[39m+\u001b[39m i\n\u001b[0;32m---> 21\u001b[0m         MSE_train[p,t,:], MSE_test[p,t,:] \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfit((input_data, output_data), \n\u001b[1;32m     22\u001b[0m                                                    (input_data_test, output_data_test),\n\u001b[1;32m     23\u001b[0m                                                    learning_rate\u001b[39m=\u001b[39mLEARNING_RATE, momentum\u001b[39m=\u001b[39mMOMENTUM, epochs\u001b[39m=\u001b[39mEPOCHS)\n\u001b[1;32m     24\u001b[0m         MSE_test_last[p,t] \u001b[39m=\u001b[39m MSE_test[p,t,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(N_INITS \u001b[39m*\u001b[39m N_SPLITS, \u001b[39m'\u001b[39m\u001b[39mtests done\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/master/ML/TP_9/mlp_backprop_momentum.py:109\u001b[0m, in \u001b[0;36mMLP.fit\u001b[0;34m(self, data_train, data_test, learning_rate, momentum, epochs)\u001b[0m\n\u001b[1;32m    106\u001b[0m                                                     \u001b[39m# Compute the weight change using the delta for this layer\u001b[39;00m\n\u001b[1;32m    107\u001b[0m                                                     \u001b[39m# and the change computed for the previous example for this layer\u001b[39;00m\n\u001b[1;32m    108\u001b[0m         delta_weights \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mlearning_rate \u001b[39m*\u001b[39m layer\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mdot(delta) \u001b[39m+\u001b[39m momentum \u001b[39m*\u001b[39m prev_delta_weights\n\u001b[0;32m--> 109\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m delta_weights            \u001b[39m# Update the weights\u001b[39;00m\n\u001b[1;32m    110\u001b[0m         prev_delta_weights \u001b[39m=\u001b[39m delta_weights          \u001b[39m# Store the delta weights for the next iteration\u001b[39;00m\n\u001b[1;32m    112\u001b[0m error_train[k] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(error_it)                  \u001b[39m# Compute the average of the error of all the examples\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (3,1) doesn't match the broadcast shape (3,2)"
     ]
    }
   ],
   "source": [
    "MSE_train = np.zeros((len(DATA_PARAMS), N_SPLITS * N_INITS, EPOCHS))\n",
    "MSE_test = np.zeros((len(DATA_PARAMS), N_SPLITS * N_INITS, EPOCHS))\n",
    "MSE_test_last = np.zeros((len(DATA_PARAMS), N_SPLITS * N_INITS))\n",
    "for p, s in enumerate(DATA_PARAMS):                                     # looping the set of parameters\n",
    "    print('Testing dataset with variance:', s)\n",
    "\n",
    "    dataset = create_dataset(DATASET_SIZE, s)\n",
    "    \n",
    "    for d in np.arange(N_SPLITS):                                       # looping the splits\n",
    "        dataset_train, dataset_test = split_dataset(dataset, TRAIN_TEST_RATIO)\n",
    "    \n",
    "        for i in np.arange(N_INITS):                                    # looping the initializations\n",
    "            sys.stdout.write('.')\n",
    "            nn = mlp.MLP([2,N_NEURONS,1], 'tanh')\n",
    "            input_data = dataset_train[:,0:nn.n_inputs]\n",
    "            output_data = dataset_train[:,nn.n_inputs:(nn.n_inputs+nn.n_outputs)]\n",
    "            input_data_test = dataset_test[:,0:nn.n_inputs]\n",
    "            output_data_test = dataset_test[:,nn.n_inputs:(nn.n_inputs+nn.n_outputs)]\n",
    "\n",
    "            t = (d * N_INITS) + i\n",
    "            MSE_train[p,t,:], MSE_test[p,t,:] = nn.fit((input_data, output_data), \n",
    "                                                       (input_data_test, output_data_test),\n",
    "                                                       learning_rate=LEARNING_RATE, momentum=MOMENTUM, epochs=EPOCHS)\n",
    "            MSE_test_last[p,t] = MSE_test[p,t,-1]\n",
    "    print(N_INITS * N_SPLITS, 'tests done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the resulting MSE, we can observe that each partition, i.e., each run of hold-out validation, generates different values of model error. For the same dataset, running hold-out validation several times does not generate coherent assessments of model error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_COL = 4\n",
    "n_rows = np.ceil(float(MSE_train.shape[0]) / MAX_COL)\n",
    "pl.figure(figsize=(12, 4 * n_rows))\n",
    "for d in range(MSE_train.shape[0]):\n",
    "    pl.subplot(int(n_rows), MAX_COL, d+1)\n",
    "    for r in range(MSE_train.shape[1]):\n",
    "        pl.plot(MSE_train[d,r,:], c='c', label='Training')\n",
    "        pl.plot(MSE_test[d,r,:], c='r', label='Testing')\n",
    "        if d == 0 and r == 0:\n",
    "            pl.legend()\n",
    "    pl.ylim(0, 0.6)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Iteration')\n",
    "    pl.title('Spread: '+str(DATA_PARAMS[d]))\n",
    "    pl.grid()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the red curves end (last iteration) at different values of MSE. Different partitions are more or less easy to learn. Some data partitions are memorized by the neural networ: which means a low training error and a high testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.boxplot(MSE_test_last.T, positions=DATA_PARAMS, widths=0.05)\n",
    "for c in np.arange(MSE_test_last.shape[1]):\n",
    "    pl.scatter(DATA_PARAMS, MSE_test_last[:,c], s=10, c='g', marker='x')\n",
    "\n",
    "pl.xlim(np.min(DATA_PARAMS)-0.1, np.max(DATA_PARAMS)+0.1)\n",
    "pl.xlabel('Spread')\n",
    "pl.ylabel('MSE')\n",
    "pl.title('Several runs of hold-out validation')\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "state": {
    "be367bcade124b30aeaf8724d3ffbbe4": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
