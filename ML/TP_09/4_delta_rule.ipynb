{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Rule\n",
    "The Delta Rule is a gradient descent approximator that can be used to find the weight values of a Perceptron. The Delta Rule minimizes an error function (tipically $E=\\frac{1}{2}(y - t)^{2}$) by adapting the weight connections in small steps. The step length is defined by the learning rate $\\alpha$. In this notebook you will explore the classification capabilities of a single Perceptron by using the delta rule. You will start by setting the connection weights by hand for a simple problem, and then you will apply the delta rule for the same problem, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Perceptron code\n",
    "In order to the make this nothebook smaller, some of the functions (activation functions, and some of the code allowing the visualization of the results) was implemented in a separate python file. You are free to open it if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import perceptron as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "The following script allows you to create a 2D dataset by using the mouse. The left click adds points belonging to class A (blue), and the right click adds points belonging to class B (red). You can create as many points as you desire. The final dataset will contain hence three values per point: x coordinate (-1 ≤ x ≤ 1), y coordinate (-1 ≤ y ≤ 1) and the class ∈ {1,-1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig = pl.figure(figsize=(6,6))\n",
    "pl.title(\"Input Dataset\")\n",
    "pl.xlim((-1.2,1.2))\n",
    "pl.ylim((-1.2,1.2))\n",
    "\n",
    "dataset = []\n",
    "\n",
    "def onclick(event):\n",
    "    global dataset\n",
    "    cx = event.xdata\n",
    "    cy = event.ydata\n",
    "    co = event.button\n",
    "    dataset.append((cx, cy, co-2))\n",
    "\n",
    "    pl.scatter(cx, cy, c=(['b', 'r'])[co > 2], s=100, lw=0)\n",
    "    pl.grid(True)\n",
    "\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.canvas.mpl_disconnect(onclick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the dataset you just created. Check that there are no NaNs in the third column. Create once again the dataset if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the weights by hand\n",
    "In this section you should try to find the set of weights that allows a Perceptron to separate the two classes you previously defined. Use the sliders to modify the value of each one of the connections and the bias of the Perceptron while trying to separate the two classes (blue and red). The curve on the right represents the classification error (MSE). If the modifications you provide improve the classification, you should see the error decreasing."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "            ______________\n",
    "           /              \\\n",
    "x __w_x__ j                l \n",
    "  _______ | f_act(I.W + b) |------ output\n",
    "y   w_y   l                j\n",
    "           \\______________/\n",
    "Where:\n",
    "x = input x\n",
    "y = input y\n",
    "b = bias\n",
    "f_act = activation function\n",
    "I = vector of inputs\n",
    "W = vector of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = pt.PerceptronPlotter2D(data=np.asarray(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_= interact(plotter.plot_interactive, **plotter.controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Delta Rule\n",
    "In the following step we propose to solve the classification problem you defined by using the delta-rule algorithm. Look at the code in compute_delta_w and try to understand it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "            ______________\n",
    "           /              \\\n",
    "x __w_x__ j                l \n",
    "  _______ | f_act(I.W + b) |------ output\n",
    "y   w_y   l                j\n",
    "           \\______________/\n",
    "Where:\n",
    "x = input x\n",
    "y = input y\n",
    "b = bias\n",
    "f_act = activation function\n",
    "I = vector of inputs\n",
    "W = vector of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ neta = (x * w\\_x) + (y * w\\_y) + b$$\n",
    "$$ output = f\\_act(neta) $$\n",
    "$$ \\Delta w\\_x = \\alpha * (target - output) * f\\_act'(neta) * x $$\n",
    "$$ \\Delta w\\_y = \\alpha * (target - output) * f\\_act'(neta) * y $$\n",
    "$$ \\Delta b = \\alpha * (target - output) * f\\_act'(neta) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta_w(inputs, weights, bias, targets, alpha, activation_function):\n",
    "    neta = np.dot(inputs, weights) + bias\n",
    "    output, d_output = activation_function(neta)\n",
    "    error = targets - output\n",
    "    d_w_x = alpha * error * d_output * inputs[:,0]\n",
    "    d_w_y = alpha * error * d_output * inputs[:,1]\n",
    "    d_b = alpha * error * d_output\n",
    "    return [d_w_x, d_w_y, d_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch learning\n",
    "When you launch the cell, the weights and the bias are initialized at random, and the algorithm perform some iterations (NUMBER_OF_EPOCHS) doing the following:\n",
    "+  for each point in the dataset, compute the modifications ( Δw ) to be done at each parameter in order to minimize the error function\n",
    "+ sum up all the modifications -> batch policy\n",
    "+ modify the weights and bias of the perceptron\n",
    "\n",
    "The cell records the effects of the modifications performed in a video. Therefore, you can visualize the learning process afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "inputs = np.asarray(dataset)[:,0:2]\n",
    "targets = np.asarray(dataset)[:,2]\n",
    "weights = np.random.normal(size=2)\n",
    "bias = np.random.normal(size=1)\n",
    "activation_function = pt.htan\n",
    "\n",
    "ALPHA = 0.1\n",
    "NUMBER_OF_EPOCHS = 30\n",
    "\n",
    "fig = pl.figure(figsize=(12, 4))\n",
    "plotter = pt.PerceptronPlotter2D(data=np.asarray(dataset))\n",
    "plotter.init_animation()\n",
    "\n",
    "def run_epoch_batch(i, alpha, inputs, weights, bias, targets, activation_function):\n",
    "    d_w_x, d_w_y, d_b = compute_delta_w(inputs, weights, bias, targets, ALPHA, activation_function)\n",
    "    weights += np.array([np.sum(d_w_x), np.sum(d_w_y)])\n",
    "    bias += np.sum(d_b)\n",
    "    \n",
    "    return plotter.data2animation(i, inputs, weights, bias, targets, activation_function)\n",
    "\n",
    "SHOW_VIDEO = True       # change this flag if you are unable to see the video\n",
    "if SHOW_VIDEO:\n",
    "    anim = animation.FuncAnimation(fig, run_epoch_batch, fargs=(ALPHA, inputs, weights, bias, targets, activation_function), frames=NUMBER_OF_EPOCHS, interval=20, blit=True)\n",
    "    pt.display_animation(anim)\n",
    "else:\n",
    "    for i in np.arange(NUMBER_OF_EPOCHS):\n",
    "        run_epoch_batch(i, ALPHA, inputs, weights, bias, targets, activation_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise\n",
    "You are free to modify the learning rate (ALPHA) and the number of iterations (NUMBER_OF_EPOCHS).\n",
    "\n",
    "Try different 2D classification problems and observe the behaviour of the algorithm in terms of:\n",
    "- Learning rate needed\n",
    "- Convergence speed\n",
    "- Oscillations\n",
    "\n",
    "Bare in mind that, in the current implementation, the parameters (weights and bias) are initialized randomly every time you launch the cell.\n",
    "\n",
    "Create some datasets as it is shown, and perform the following tests:\n",
    "\n",
    "1. What happens if the boundaries between both classes are well defined?\n",
    "![separable](separable.png)\n",
    "\n",
    "2. What happens if the classes overlap? What could you say about oscillations in the error signal?\n",
    "![overlapping](overlapping.png)\n",
    "\n",
    "3. What happens if it is not possible to separate the classes with a single line? What could you say about local minima?\n",
    "![non_separable](non_separable.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
