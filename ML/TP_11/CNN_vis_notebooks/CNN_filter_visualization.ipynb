{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RtHIDh84bX2W"},"source":["# Understanding Convolutional Neural Networks\n","This notebook will guide you through the use of the `keras` package to train convolutional neural networks for handwritten digit classification and will propose a series of visualization tools, based on filter activation statistics, to better understand how the CNN is accomplishing its task. "]},{"cell_type":"markdown","metadata":{"id":"JE4apfHkbX2a"},"source":["## Loading the packages"]},{"cell_type":"code","metadata":{"id":"a6E-V7I1bX9a"},"source":["%pip install tensorflow --upgrade\n","%pip install keras --upgrade"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HnPp6WsmbX2k"},"source":["import numpy as np\n","from matplotlib import pyplot as pl\n","\n","from keras.datasets import mnist\n","from keras.models import Model\n","from keras.layers.core import Dense, Dropout, Flatten\n","from tensorflow.keras.optimizers import RMSprop\n","from keras.utils import np_utils\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.layers import Input\n","from sklearn import metrics as me\n","from scipy import stats\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ieapUkaDbX28"},"source":["First, create some useful functions"]},{"cell_type":"code","metadata":{"id":"n2eVP1AtbX3A"},"source":["def build_grid_of_images(array):\n","    assert len(array.shape) == 3\n","    array = np.rollaxis(array, 2, 0)\n","    dim_0 = np.sqrt(array.shape[0])\n","    assert dim_0.is_integer()\n","    dim_0 = int(dim_0)\n","    \n","    temp_out = np.reshape(array, (dim_0, dim_0, array.shape[1], array.shape[2]))\n","    temp_out = np.rollaxis(temp_out, 1, 3)\n","    return np.reshape(temp_out, (dim_0*array.shape[1], dim_0*array.shape[2]))\n","\n","#a = np.array(np.arange(36))\n","#print(a)\n","\n","#b = np.reshape(a, (4,3,3))\n","#print(b[0,:,:])\n","#print(b[1,:,:])\n","\n","#c = build_grid_of_images(b)\n","#print c\n","\n","def plot_conv_layer_output(temp_out, title):\n","    temp_to_plot = build_grid_of_images(temp_out)\n","    pl.imshow(temp_to_plot, interpolation='nearest', cmap=pl.get_cmap('Greys'))\n","    ax = pl.gca()\n","    ax.set_xticks(np.arange(-0.5, temp_to_plot.shape[0]+0.5, temp_out.shape[0]))    \n","    ax.set_yticks(np.arange(-0.5, temp_to_plot.shape[0]+0.5, temp_out.shape[1]))\n","    pl.grid()\n","    pl.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n","    pl.title(title)\n","\n","def plot_dense_layer_output(temp_out, title):\n","    pl.bar(np.arange(temp_out.shape[1])-0.4, temp_out[0,:])\n","    pl.xlim(-0.5, temp_out.shape[1])\n","    pl.grid()\n","    pl.title(title)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"svaqBss5bX3M"},"source":["Load the `mnist` dataset and normalize in the range [0, 1]"]},{"cell_type":"code","metadata":{"id":"65DvWwWmbX3N"},"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","n_train, height, width = X_train.shape\n","n_test, _, _ = X_test.shape\n","\n","X_train = X_train.reshape(n_train, height, width, 1).astype('float32')\n","X_test = X_test.reshape(n_test, height, width, 1).astype('float32')\n","\n","X_train /= 255.0\n","X_test /= 255.0\n","\n","n_classes = 10\n","\n","print(n_train, 'train samples')\n","print(n_test, 'test samples')\n","\n","# convert class vectors to binary class matrices\n","Y_train = np_utils.to_categorical(y_train, n_classes)\n","Y_test = np_utils.to_categorical(y_test, n_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JYaYEBWXbX3f"},"source":["Create the CNN and show its architecture"]},{"cell_type":"code","metadata":{"id":"eEzJ-KDobX3g"},"source":["l0 = Input(shape=(height, width, 1), name='l0')\n","\n","l1 = Conv2D(9, (5, 5), padding='same', activation='relu', name='l1')(l0)\n","l1_mp = MaxPooling2D(pool_size=(2, 2), name='l1_mp')(l1)\n","\n","l2 = Conv2D(9, (5, 5), padding='same', activation='relu', name='l2')(l1_mp)\n","l2_mp = MaxPooling2D(pool_size=(2, 2), name='l2_mp')(l2)\n","\n","l3 = Conv2D(16, (3, 3), padding='same', activation='relu', name='l3')(l2_mp)\n","l3_mp = MaxPooling2D(pool_size=(2, 2), name='l3_mp')(l3)\n","\n","flat = Flatten(name='flat')(l3_mp)\n","\n","l4 = Dense(25, activation='relu', name='l4')(flat)\n","\n","l5 = Dense(n_classes, activation='softmax', name='l5')(l4)\n","\n","model = Model(inputs=l0, outputs=l5)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2wONs60HbX3t"},"source":["Define some constants and train de CNN"]},{"cell_type":"code","metadata":{"id":"ZhRLluBfbX3x"},"source":["batch_size = 256\n","n_epoch = 10\n","\n","model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n","history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=n_epoch, verbose=1, validation_data=(X_test, Y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OQQ3O7dVbX36"},"source":["Show the performance of the model"]},{"cell_type":"code","metadata":{"id":"HNOVXpOAbX4A"},"source":["pl.plot(history.history['loss'], label='Training')\n","pl.plot(history.history['val_loss'], label='Testing')\n","pl.legend()\n","pl.grid()\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l6ZjxZiXbX4M"},"source":["Confusion matrix"]},{"cell_type":"code","metadata":{"id":"faUksaK5bX4O"},"source":["pred = model.predict_on_batch(X_test)\n","pred = np.argmax(pred, axis=-1)\n","me.confusion_matrix(y_test, pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lgZd8nRXbX4R"},"source":["## Testing the behaviour of each layer\n","\n","Artificial neural networks are considered black-box models in which it is very difficult to understand the meaning of the model parameters (weights).\n","The following cells show some approaches which should ease the understanding of how a CNN works, or what kind of features are encoded in the internal filters of the network"]},{"cell_type":"code","metadata":{"id":"zayJotWdbX4U"},"source":["l1_o = Model(inputs=l0, outputs=l1)\n","l1_mp_o = Model(inputs=l0, outputs=l1_mp)\n","l2_o = Model(inputs=l0, outputs=l2)\n","l2_mp_o = Model(inputs=l0, outputs=l2_mp)\n","l3_o = Model(inputs=l0, outputs=l3)\n","l3_mp_o = Model(inputs=l0, outputs=l3_mp)\n","flat_o = Model(inputs=l0, outputs=flat)\n","l4_o = Model(inputs=l0, outputs=l4)\n","l5_o = Model(inputs=l0, outputs=l5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iEhcPjeQbX4W"},"source":["Do the test with one input from the test set"]},{"cell_type":"code","metadata":{"id":"Ymz1RcXhbX4X"},"source":["current_input = X_test[0:1,:,:,0:1]\n","pl.figure(figsize=(5,5))\n","pl.imshow(current_input[0,:,:,0], interpolation='nearest', cmap=pl.get_cmap('Greys'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bQuN81MVbX4b"},"source":["### Visualize the output of each layer"]},{"cell_type":"code","metadata":{"id":"rPKJR0LJbX4b"},"source":["pl.figure(figsize=(12,10))\n","\n","pl.subplot(2,3,1)\n","temp_out = l1_o.predict(current_input)[0,:,:,:]\n","plot_conv_layer_output(temp_out, 'first_layer')\n","\n","pl.subplot(2,3,2)\n","temp_out = l2_o.predict(current_input)[0,:,:,:]\n","plot_conv_layer_output(temp_out, 'second_layer')\n","\n","pl.subplot(2,3,3)\n","temp_out = l3_o.predict(current_input)[0,:,:,:]\n","plot_conv_layer_output(temp_out, 'third_layer')\n","\n","pl.subplot(6,1,4)\n","temp_out = flat_o.predict(current_input)\n","plot_dense_layer_output(temp_out, 'third layer flattened')\n","\n","pl.subplot(6,1,5)\n","temp_out = l4_o.predict(current_input)\n","plot_dense_layer_output(temp_out, 'fourth layer')\n","\n","pl.subplot(6,1,6)\n","temp_out = l5_o.predict(current_input)\n","plot_dense_layer_output(temp_out, 'fifth layer')\n","\n","pl.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UTsNqEx0bX4g"},"source":["For a given input image, the previous cell shows how the different filters of the network generate internal representations of the input image. The first layers are easier to interpret since they contain more spatial information (e.g., edges or blobs). On the other hand, deeper layers (fourth layer) are more difficult to understand because the spatial information and the salient details of the different classes are encoded in the internal representation of the network."]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"b-u61o8nbX4j"},"source":["### Visualize the average output of each layer\n","Let's do the same for the whole set of training images and then compute the average activation of each layer"]},{"cell_type":"code","metadata":{"id":"WyLHVO-ObX4j"},"source":["all_l1 = l1_o.predict(X_train)\n","all_l1_by_class = np.zeros((n_classes,) + all_l1.shape[1:4])\n","for i in np.arange(n_classes):\n","    all_l1_by_class[i,:,:,:] = np.mean(all_l1[Y_train[:,i] == 1.0], axis=0)\n","\n","all_l2 = l2_o.predict(X_train)\n","all_l2_by_class = np.zeros((n_classes,) + all_l2.shape[1:4])\n","for i in np.arange(n_classes):\n","    all_l2_by_class[i,:,:,:] = np.mean(all_l2[Y_train[:,i] == 1.0], axis=0)\n","\n","all_l3 = l3_o.predict(X_train)\n","all_l3_by_class = np.zeros((n_classes,) + all_l3.shape[1:4])\n","for i in np.arange(n_classes):\n","    all_l3_by_class[i,:,:,:] = np.mean(all_l3[Y_train[:,i] == 1.0], axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zU_HBk8ybX4o"},"source":["Visualize the average activation of each layer per class"]},{"cell_type":"code","metadata":{"id":"Ymp_D-v5bX4o","scrolled":false},"source":["pl.figure(figsize=(10,30))\n","for i in np.arange(n_classes):\n","    pl.subplot(10,3,3*i+1)\n","    plot_conv_layer_output(all_l1_by_class[i,:,:,:], str(i))\n","    pl.subplot(10,3,3*i+2)\n","    plot_conv_layer_output(all_l2_by_class[i,:,:,:], str(i))\n","    pl.subplot(10,3,3*i+3)\n","    plot_conv_layer_output(all_l3_by_class[i,:,:,:], str(i))\n","pl.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"18GfFpmGbX4q"},"source":["### Visualize which filter is activated most of the time for each pixel\n","The following cells find the index of the filter with the highest activation, and then compute the mode through the whole dataset"]},{"cell_type":"code","metadata":{"id":"qm6yH1JZbX4r"},"source":["l1_f = np.zeros((n_classes, ) + all_l1.shape[1:3])\n","for i in np.arange(n_classes):\n","    temp = np.argmax(all_l1[Y_train[:,i] == 1.0], axis=3)\n","    l1_f[i,:,:] = stats.mode(temp, axis=0)[0]\n","l2_f = np.zeros((n_classes,) + all_l2.shape[1:3])\n","for i in np.arange(n_classes):\n","    temp = np.argmax(all_l2[Y_train[:,i] == 1.0], axis=3)\n","    l2_f[i,:,:] = stats.mode(temp, axis=0)[0]\n","l3_f = np.zeros((n_classes,) + all_l3.shape[1:3])\n","for i in np.arange(n_classes):\n","    temp = np.argmax(all_l3[Y_train[:,i] == 1.0], axis=3)\n","    l3_f[i,:,:] = stats.mode(temp, axis=0)[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMXpdrkAbX4v"},"source":["pl.figure(figsize=(12,5))\n","for i in np.arange(n_classes):\n","    pl.subplot(2,5,i+1)\n","    pl.imshow(l1_f[i], interpolation='nearest', cmap=pl.get_cmap('Set1', all_l1.shape[3]), vmin=0, vmax=all_l1.shape[3]-1)\n","    pl.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n","    pl.colorbar(values=np.arange(all_l1.shape[3]),\n","                boundaries=np.arange(all_l1.shape[3]+1)-0.5,\n","                ticks=np.arange(all_l1.shape[3]), shrink=0.8)\n","pl.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-qKCMBbbX4x"},"source":["pl.figure(figsize=(12,5))\n","for i in np.arange(n_classes):\n","    pl.subplot(2,5,i+1)\n","    pl.imshow(l2_f[i], interpolation='nearest', cmap=pl.get_cmap('Set1', all_l2.shape[3]), vmin=0, vmax=all_l2.shape[3]-1)\n","    pl.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n","    pl.colorbar(values=np.arange(all_l2.shape[3]),\n","                boundaries=np.arange(all_l2.shape[3]+1)-0.5,\n","                ticks=np.arange(all_l2.shape[3]), shrink=0.8)\n","pl.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zj1oTALLbX42"},"source":["pl.figure(figsize=(12,5))\n","for i in np.arange(n_classes):\n","    pl.subplot(2,5,i+1)\n","    pl.imshow(l3_f[i], interpolation='nearest', cmap=pl.get_cmap('Set1', all_l3.shape[3]), vmin=0, vmax=all_l3.shape[3]-1)\n","    pl.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n","    pl.colorbar(values=np.arange(all_l3.shape[3]),\n","                boundaries=np.arange(all_l3.shape[3]+1)-0.5,\n","                ticks=np.arange(all_l3.shape[3]), shrink=0.8)\n","pl.tight_layout()"],"execution_count":null,"outputs":[]}]}