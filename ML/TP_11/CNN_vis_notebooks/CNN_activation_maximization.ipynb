{"cells":[{"cell_type":"markdown","metadata":{"id":"imWIDTjPZJxm"},"source":["# Activation maximization\n","\n","This notebook will guide you through the use of a widely used technique for studying the behaviour of convolutional neural networks. You will use a python package called `keras-vis` to apply a technique called `activation maximization`:\n","\n","The idea behind activation maximization is simple: generate an input image that maximizes the output activations of a given unit (filter) in the network.\n","\n","The `keras-vis` package computes the derivative of the ActivationMaximization loss with respect to the input, and uses this gradient to update the input image. ActivationMaximization loss simply outputs small values for large filter activations (the package minimizes losses during gradient descent iterations). This allows us to understand what sort of input patterns activate a particular filter. For example, for detecting the digit one (1) there could be a filter that activates for the presence of vertical lines within the input image.\n","\n","For the experiments, you are going to use the `mnist` dataset from LeCun et al. 1998."]},{"cell_type":"markdown","metadata":{"id":"tc8E5mhZZJxp"},"source":["------------------------------------------------\n","# First part: Creating a model"]},{"cell_type":"markdown","metadata":{"id":"e9ptRYj3ZJxz"},"source":["## Loading the packages"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3pja6pvggqCt"},"outputs":[],"source":["import sys\n","sys.setrecursionlimit(10000)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1T3U4OlKjkv4"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-06 09:13:53.425822: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-06 09:13:53.556882: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2022-12-06 09:13:53.556900: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","2022-12-06 09:13:53.581969: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-12-06 09:13:54.365167: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2022-12-06 09:13:54.365228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2022-12-06 09:13:54.365236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import tensorflow as tf\n","\n","tf.compat.v1.disable_eager_execution()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ob1LHDtsZJx3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting tensorflow==2.7\n","  Downloading tensorflow-2.7.0-cp38-cp38-manylinux2010_x86_64.whl (489.6 MB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.6/489.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting keras==2.7\n","  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hCollecting wheel<1.0,>=0.32.0\n","  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (0.27.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (1.6.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (1.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (4.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (0.2.0)\n","Requirement already satisfied: libclang>=9.0.1 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (14.0.6)\n","Requirement already satisfied: absl-py>=0.4.0 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (1.2.0)\n","Requirement already satisfied: six>=1.12.0 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (1.16.0)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (0.4.0)\n","Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n","  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (1.42.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (3.19.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (1.13.3)\n","Requirement already satisfied: numpy>=1.14.5 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (1.21.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (3.3.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (1.1.2)\n","Requirement already satisfied: h5py>=2.9.0 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (3.6.0)\n","Requirement already satisfied: tensorboard~=2.6 in /home/thomas/.local/lib/python3.8/site-packages (from tensorflow==2.7) (2.10.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/thomas/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7) (0.6.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /home/thomas/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7) (2.0.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/thomas/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7) (1.8.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow==2.7) (45.2.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /home/thomas/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7) (2.28.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /home/thomas/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7) (2.3.3)\n","Requirement already satisfied: markdown>=2.6.8 in /home/thomas/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/thomas/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7) (0.4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/thomas/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/thomas/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (0.2.8)\n","Collecting requests-oauthlib>=0.7.0\n","  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: importlib-metadata>=4.4 in /home/thomas/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7) (4.8.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (2.8)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/thomas/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (1.26.12)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /home/thomas/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (2019.11.28)\n","Requirement already satisfied: zipp>=0.5 in /home/thomas/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/thomas/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7) (3.1.0)\n","Installing collected packages: tensorflow-estimator, keras, wheel, requests-oauthlib, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.10.0\n","    Uninstalling tensorflow-estimator-2.10.0:\n","      Successfully uninstalled tensorflow-estimator-2.10.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.10.0\n","    Uninstalling keras-2.10.0:\n","      Successfully uninstalled keras-2.10.0\n","  Attempting uninstall: wheel\n","    Found existing installation: wheel 0.30.0\n","    Uninstalling wheel-0.30.0:\n","      Successfully uninstalled wheel-0.30.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.10.0\n","    Uninstalling tensorflow-2.10.0:\n","      Successfully uninstalled tensorflow-2.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","msrest 0.6.21 requires isodate>=0.6.0, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.7.0 requests-oauthlib-1.3.1 tensorflow-2.7.0 tensorflow-estimator-2.7.0 wheel-0.38.4\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n","    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n","    extend(render(renderable, render_options))\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n","    for render_output in iter_render:\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n","    for line in lines:\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n","    for segment in segments:\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n","    renderable = rich_cast(renderable)\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n","    renderable = cast_method()\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n","    pip_cmd = get_best_invocation_for_this_pip()\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n","    if found_executable and os.path.samefile(\n","  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n","    s2 = os.stat(f2)\n","FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip3.8'\n","Call stack:\n","  File \"/home/thomas/.local/bin/pip\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_internal/cli/main.py\", line 70, in main\n","    return command.main(cmd_args)\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n","    return self._main(args)\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n","    self.handle_pip_version_check(options)\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n","    pip_self_version_check(session, options)\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n","    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n","    self._log(WARNING, msg, args, **kwargs)\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n","    self.emit(record)\n","  File \"/home/thomas/.local/lib/python3.8/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n","    self.handleError(record)\n","Message: '[present-rich] %s'\n","Arguments: (UpgradePrompt(old='22.2.2', new='22.3.1'),)\n","Defaulting to user installation because normal site-packages is not writeable\n","Collecting scipy==1.2.*\n","  Downloading scipy-1.2.3.tar.gz (23.3 MB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: scipy\n","  Building wheel for scipy (setup.py) ... \u001b[?25l/"]}],"source":["!pip install tensorflow==2.7 keras==2.7\n","!pip install -I scipy==1.2.*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTyeINkBKzbC"},"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as pl\n","\n","from keras.datasets import mnist\n","from keras.models import Model\n","from keras.layers.core import Dense, Dropout, Flatten\n","from tensorflow.keras.optimizers import RMSprop\n","from keras.utils import np_utils\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.layers import Input\n","from sklearn import metrics as me\n","from scipy import stats\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"e6up2m5IZJyS"},"source":["## Loading the data"]},{"cell_type":"markdown","metadata":{"id":"bOR9KEnCZJyZ"},"source":["Load the `mnist` dataset and normalize in the range [0, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JXCIiSYaZJya"},"outputs":[],"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","n_train, height, width = X_train.shape\n","n_test, _, _ = X_test.shape\n","\n","X_train = X_train.reshape(n_train, height, width, 1).astype('float32')\n","X_test = X_test.reshape(n_test, height, width, 1).astype('float32')\n","\n","X_train /= 255.0\n","X_test /= 255.0\n","\n","n_classes = 10\n","\n","print(n_train, 'train samples')\n","print(n_test, 'test samples')\n","\n","# convert class vectors to binary class matrices\n","Y_train = np_utils.to_categorical(y_train, n_classes)\n","Y_test = np_utils.to_categorical(y_test, n_classes)"]},{"cell_type":"markdown","metadata":{"id":"PEpZac5JZJyj"},"source":["## Creating the network"]},{"cell_type":"markdown","metadata":{"id":"63eMtWFxZJyp"},"source":["Create the CNN and show its architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7J4_2sTfZJys"},"outputs":[],"source":["l0 = Input(shape=(height, width, 1), name='l0')\n","\n","l1 = Conv2D(9, (5, 5), padding='same', activation='relu', name='l1')(l0)\n","l1_mp = MaxPooling2D(pool_size=(2, 2), name='l1_mp')(l1)\n","\n","l2 = Conv2D(9, (5, 5), padding='same', activation='relu', name='l2')(l1_mp)\n","l2_mp = MaxPooling2D(pool_size=(2, 2), name='l2_mp')(l2)\n","\n","l3 = Conv2D(16, (3, 3), padding='same', activation='relu', name='l3')(l2_mp)\n","l3_mp = MaxPooling2D(pool_size=(2, 2), name='l3_mp')(l3)\n","\n","flat = Flatten(name='flat')(l3_mp)\n","\n","l4 = Dense(25, activation='relu', name='l4')(flat)\n","\n","l5 = Dense(n_classes, activation='softmax', name='l5')(l4)\n","\n","model = Model(inputs=l0, outputs=l5)\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"yvvTlJJSZJy_"},"source":["## Training the network"]},{"cell_type":"markdown","metadata":{"id":"jZpbkamGZJzA"},"source":["Define some constants and train de CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DKWZxlE9ZJzC"},"outputs":[],"source":["batch_size = 128\n","n_epoch = 10\n","\n","model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n","history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=n_epoch, verbose=1, validation_data=(X_test, Y_test))"]},{"cell_type":"markdown","metadata":{"id":"ViQCrGZHZJzP"},"source":["Show the performance of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NmyJTjiKZJzU"},"outputs":[],"source":["pl.plot(history.history['loss'], label='Training')\n","pl.plot(history.history['val_loss'], label='Testing')\n","pl.legend()\n","pl.grid()\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"]},{"cell_type":"markdown","metadata":{"id":"0rrwvLEJZJzp"},"source":["Confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FR8MPGY9ZJzq"},"outputs":[],"source":["pred = model.predict_on_batch(X_test)\n","pred = np.argmax(pred, axis=-1)\n","me.confusion_matrix(y_test, pred)"]},{"cell_type":"markdown","metadata":{"id":"Q5ZZQIF9ZJzt"},"source":["-------------------------\n","# Second part: maximizing activations"]},{"cell_type":"markdown","metadata":{"id":"KZt_yVZLZJzt"},"source":["## Loading the packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iP0BOXaSx1zw"},"outputs":[],"source":["!pip install git+https://github.com/SimWalther/keras-vis.git -U"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JrnCYuOSZJzw"},"outputs":[],"source":["from __future__ import print_function\n","from vis.visualization import visualize_activation\n","from vis.utils import utils\n","from keras import activations\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nG8nOa52QgyP"},"outputs":[],"source":["from vis.utils import utils\n","from vis.visualization import visualize_cam, overlay"]},{"cell_type":"markdown","metadata":{"id":"pahxlVXqZJzy"},"source":["## Activation maximization keeping the softmax activation at the output\n","Activation maximization does not work if the activation function is a Softmax. Let us see this behaviour"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R8qyb4ynZJzz"},"outputs":[],"source":["# select the last layer\n","layer_idx = utils.find_layer_idx(model, 'l5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O0ytYLi8ZJz0"},"outputs":[],"source":["pl.figure(figsize=(12,10))\n","for output_idx in np.arange(10):\n","    img = visualize_activation(model, layer_idx, filter_indices=int(output_idx), input_range=(0.0, 1.0))\n","    pl.subplot(3, 4, output_idx+1)\n","    pl.title('Maximization of output {}'.format(output_idx))\n","    pl.imshow(img[..., 0])\n","pl.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"TgYNx4NPZJz6"},"source":["It does not work! The reason is that when using Softmax as activation function, maximizing an output node can be done by minimizing other outputs. It is the only activation that depends on other node output(s) in the layer."]},{"cell_type":"markdown","metadata":{"id":"DjnkS6BmZJz7"},"source":["## Activation maximization without the softmax activation at the output"]},{"cell_type":"markdown","metadata":{"id":"BaYAAJa4ZJz7"},"source":["The following cell replaces the Softmax activation function by a Linear activation function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yvGzheAyZJz8"},"outputs":[],"source":["model.layers[layer_idx].activation = activations.linear\n","model = utils.apply_modifications(model)"]},{"cell_type":"markdown","metadata":{"id":"My22iKA8ZJz-"},"source":["Visualize the image that maximizes the first output (0) of the network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fKVQwgj6ZJz-"},"outputs":[],"source":["#img = visualize_activation(model, layer_idx, filter_indices=0, input_range=(0.0, 1.0), tv_weight=0)\n","#pl.imshow(img[..., 0])\n","\n","# ADDED\n","tv_weight=[0.125, 0.25, 0.5, 1, 2, 4, 8, 16]\n","pl.figure(figsize=(12,10))\n","for i in range(8):\n","    img = visualize_activation(model, layer_idx, filter_indices=0, input_range=(0.0, 1.0), tv_weight=tv_weight[i])\n","    pl.subplot(2, 4, i+1)\n","    pl.title('tv_weight={}'.format(tv_weight[i]))\n","    pl.imshow(img[..., 0])\n","pl.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELL ADDED\n","\n","best_tv_weight = 0.5 # seems to be the best tv_weight\n","\n","pl.figure(figsize=(12,10))\n","for output_idx in np.arange(10):\n","    img = visualize_activation(model, layer_idx, filter_indices=int(output_idx), input_range=(0.0, 1.0), tv_weight=best_tv_weight)\n","    pl.subplot(3, 4, output_idx+1)\n","    pl.title('Maximization of output {}'.format(output_idx))\n","    pl.imshow(img[..., 0])\n","pl.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"CE_RKPGLZJ0A"},"source":["The last result was found without using the `tv_weight` regularizer (tv_weight=0.0). However, we know that using the parameter tv_weight makes the generated image more realistic."]},{"cell_type":"markdown","metadata":{"id":"Fk7rwAPWZJ0B"},"source":["## Questions"]},{"cell_type":"markdown","metadata":{"id":"MmCJT7jAZJ0F"},"source":["<div class=\"alert alert-block alert-info\">\n","<ul>\n","    <li>Test different values of `tv_weight`</li>\n","    <ul>\n","        <li>Try values between 0.1 and 20 (for example: [0.125, 0.25, 0.5, 1, 2, 4, 8, 16])</li>\n","        <li>Select the regularization parameter that gives the best images (more realistic)</li>\n","        <li>Show the images that maximize each one of the outputs of the network</li>\n","    </ul>\n","    <li>Maximize two outputs at the same time (filter_indices=[f1, f2])</li>\n","    <ul>\n","        <li>Try two classes with similar shape like 1 and 7 or 4 and 9</li>\n","        <li>Try two classes with very different shapes like 0 and 1 or 7 and 8</li>\n","        <li>How activation maximization can be useful for understanding a deep neural network? Explain</li>\n","    </ul>\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mC38yfxog-xL"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
