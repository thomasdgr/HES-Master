{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with TensorFlow 2.0\n",
    "The objective of the exercise is to implement computational graphs in TensorFlow 2.0 to train and use such an architecture. The constraints we put ourselves is to use **low-level** functions of TensorFlow, i.e. we will not use high-level functions to compose layers and to train the parameters.\n",
    "\n",
    "If you get this error in the execution of the first cell: ` ModuleNotFoundError: No module named 'tensorflow' `, it probably means TensorFlow 2.0 is not installed yet on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:29:54.046919: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-06 18:29:54.268081: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-06 18:29:54.269371: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-06 18:29:55.249938: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data set ready. N=60000, D=784, n_classes=10\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# MNIST Dataset Preparation #\n",
    "#############################\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train_vec),(x_test, y_test_vec) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train_vec, 10, dtype='float64')\n",
    "y_test = tf.keras.utils.to_categorical(y_test_vec, 10, dtype='float64')\n",
    "N = x_train.shape[0]         # number of samples\n",
    "D = x_train.shape[1]         # dimension of input sample\n",
    "n_classes = y_train.shape[1] # output dim\n",
    "print('MNIST data set ready. N={}, D={}, n_classes={}'.format(N,D,n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample a random batch from dataset\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0,len(data))  # create an array of index values\n",
    "    np.random.shuffle(idx)        # shuffle it\n",
    "    idx = idx[:num]               # take the first n indexes = size of batch\n",
    "    data_shuffle = data[idx]      # extract the batch using the random indexes\n",
    "    labels_shuffle = labels[idx]  # extract the labels using the random indexes\n",
    "\n",
    "    return data_shuffle, labels_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, loss = 58.64231472273458\n",
      "epoch = 1, loss = 41.67887502238665\n",
      "epoch = 2, loss = 39.081965981569844\n",
      "epoch = 3, loss = 36.90061370169597\n",
      "epoch = 4, loss = 34.96542616959415\n",
      "epoch = 5, loss = 33.136729352088516\n",
      "epoch = 6, loss = 31.418740955476583\n",
      "epoch = 7, loss = 29.823219388586626\n",
      "epoch = 8, loss = 28.59631071182218\n",
      "epoch = 9, loss = 27.165810394682904\n",
      "epoch = 10, loss = 26.124461224331046\n",
      "epoch = 11, loss = 25.058146323621816\n",
      "epoch = 12, loss = 24.094200523372596\n",
      "epoch = 13, loss = 23.30828834862135\n",
      "epoch = 14, loss = 22.62111297472997\n",
      "epoch = 15, loss = 21.88691228561025\n",
      "epoch = 16, loss = 21.23659777364404\n",
      "epoch = 17, loss = 20.60964401648701\n",
      "epoch = 18, loss = 19.985446552985398\n",
      "epoch = 19, loss = 19.652857550651095\n",
      "epoch = 20, loss = 19.07323464485052\n",
      "epoch = 21, loss = 18.679740631611264\n",
      "epoch = 22, loss = 18.414552721749597\n",
      "epoch = 23, loss = 17.92366202587079\n",
      "epoch = 24, loss = 17.58571805017423\n",
      "epoch = 25, loss = 17.278713541874616\n",
      "epoch = 26, loss = 16.982988977695584\n",
      "epoch = 27, loss = 16.77587885534404\n",
      "epoch = 28, loss = 16.411049137271664\n",
      "epoch = 29, loss = 16.116935918676354\n",
      "epoch = 30, loss = 15.946802691461782\n",
      "epoch = 31, loss = 15.656028526311028\n",
      "epoch = 32, loss = 15.496974579673576\n",
      "epoch = 33, loss = 15.349975665489087\n",
      "epoch = 34, loss = 15.076886019922053\n",
      "epoch = 35, loss = 14.926738206534116\n",
      "epoch = 36, loss = 14.69186269729572\n",
      "epoch = 37, loss = 14.372530749358438\n",
      "epoch = 38, loss = 14.291371617512553\n",
      "epoch = 39, loss = 14.221120622704362\n",
      "epoch = 40, loss = 13.939536826884867\n",
      "epoch = 41, loss = 13.831714453361794\n",
      "epoch = 42, loss = 13.75681952263483\n",
      "epoch = 43, loss = 13.589403602714253\n",
      "epoch = 44, loss = 13.339386906817007\n",
      "epoch = 45, loss = 13.378253951345263\n",
      "epoch = 46, loss = 13.342128950638104\n",
      "epoch = 47, loss = 13.117708771802263\n",
      "epoch = 48, loss = 13.132399078110902\n",
      "epoch = 49, loss = 12.920551313352025\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Training phase #\n",
    "##################\n",
    "\n",
    "E = 50                # number of epochs\n",
    "B = 128               # batch size\n",
    "N = x_train.shape[0]  # number of samples\n",
    "D = x_train.shape[1]  # dimension of input sample\n",
    "H = 300               # number of neurons\n",
    "A = 0.01              # learning rate alpha\n",
    "\n",
    "##############################################\n",
    "#  COMPLETE CODE BELOW WHERE YOU SEE # ...   #\n",
    "##############################################\n",
    "\n",
    "# Build the computational graph\n",
    "@tf.function # this decorator tells tf that a graph is defined\n",
    "def mlp_train(x, y, alpha):\n",
    "    # define nodes for forward computation for hidden neurons h and output neurons y_pred\n",
    "    h = tf.nn.relu(tf.matmul(x, w1) + b1)  # output of first layer after ReLu activation\n",
    "    y_pred = tf.nn.sigmoid(tf.matmul(h, w2) + b2) # output of second layer after sigmoid activation\n",
    "    # define nodes for forward computation for hidden neurons h and output neurons y_pred\n",
    "    diff = y_pred - y\n",
    "    loss = tf.reduce_mean(tf.square(diff))\n",
    "    # define the gradients\n",
    "    grad_w1, grad_b1, grad_w2, grad_b2 =  tf.gradients(ys=loss, xs=[w1, b1, w2, b2])\n",
    "    # compute the new values of the gradients with the assign method (see slides)\n",
    "    w1.assign(w1 - alpha * grad_w1)\n",
    "    b1.assign(b1 - alpha * grad_b1)\n",
    "    w2.assign(w2 - alpha * grad_w2)\n",
    "    b2.assign(b2 - alpha * grad_b2)\n",
    "    return y_pred, loss\n",
    "\n",
    "# Init the tf.Variablesw 1, b1, w2, b2 following the given examples\n",
    "w1 = tf.Variable(tf.random.truncated_normal((D, H), stddev = 0.1, dtype='float64'))\n",
    "b1 = tf.Variable(tf.constant(0.0, shape=[H], dtype='float64'))\n",
    "w2 = tf.Variable(tf.random.truncated_normal((H, n_classes), stddev = 0.1, dtype='float64'))\n",
    "b2 = tf.Variable(tf.constant(0.0, shape=[n_classes], dtype='float64'))\n",
    "\n",
    "# Run the computational graph\n",
    "J = [] # to store the evolution of loss J for each epoch\n",
    "for epoch in range(E):\n",
    "    J_epoch = 0.0\n",
    "    for _ in range(int(N/B)): # number of batches to visit for 1 epoch\n",
    "        # get batches calling the next_batch method provided above\n",
    "        x_train_batch, y_train_batch = next_batch(B, x_train, y_train)\n",
    "        with tf.device('/CPU:0'):  # change to /GPU:0 to move it to GPU\n",
    "            # call the graph with the batched input, target and alpha A\n",
    "            out = mlp_train(x_train_batch, y_train_batch, A)\n",
    "        y_pred, loss_val = out\n",
    "        J_epoch += loss_val\n",
    "    J.append(J_epoch)\n",
    "    print(\"epoch = {}, loss = {}\".format(epoch, J_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb0486e2530>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the evolution of the loss\n",
    "plt.plot(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass on test set done.\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Testing phase #\n",
    "#################\n",
    "\n",
    "N = x_test.shape[0]  # number of samples\n",
    "D = x_test.shape[1]  # dimension of input sample\n",
    "\n",
    "##############################################\n",
    "#  COMPLETE CODE BELOW WHERE YOU SEE # ...   #\n",
    "##############################################\n",
    "# Build the computational graph\n",
    "@tf.function # this decorator tells tf that a graph is defined\n",
    "def mlp_test(x, y):\n",
    "    h = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "    y_pred = tf.matmul(h, w2) + b2\n",
    "    return y_pred\n",
    "\n",
    "# Run the computational graph\n",
    "with tf.device('/CPU:0'):  # change to /GPU:0 to move it to GPU\n",
    "    y_pred_test = mlp_test(x_test, y_test)\n",
    "\n",
    "print('Forward pass on test set done.')\n",
    "# At this stage, y_pred_test should contain the matrix of outputs on the test set with shape (N_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples  :  10000\n",
      "# correct  :  8786\n",
      "# missed   :  1214\n",
      "accuracy   :  87.86 %\n",
      "error rate :  12.14 %\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "y_winner = np.argmax(y_pred_test, axis=1)\n",
    "N_test = y_winner.size\n",
    "num_correct = (y_winner == y_test_vec).sum()\n",
    "num_missed = N_test - num_correct\n",
    "accuracy = num_correct * 1.0 / N_test\n",
    "error_rate = num_missed * 1.0 / N_test\n",
    "print('# samples  : ', N_test)\n",
    "print('# correct  : ', num_correct)\n",
    "print('# missed   : ', num_missed)\n",
    "print('accuracy   :  %2.2f %%'% (accuracy*100.0))\n",
    "print('error rate :  %2.2f %%'% (error_rate*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0947 - accuracy: 0.3253\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0734 - accuracy: 0.5600\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0613 - accuracy: 0.6874\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0525 - accuracy: 0.7395\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0466 - accuracy: 0.7751\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0423 - accuracy: 0.8174\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0389 - accuracy: 0.8408\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0361 - accuracy: 0.8520\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0339 - accuracy: 0.8581\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0321 - accuracy: 0.8630\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0306 - accuracy: 0.8674\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0294 - accuracy: 0.8711\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0283 - accuracy: 0.8739\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0274 - accuracy: 0.8763\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0266 - accuracy: 0.8788\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0259 - accuracy: 0.8811\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0252 - accuracy: 0.8828\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0246 - accuracy: 0.8847\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0241 - accuracy: 0.8867\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0236 - accuracy: 0.8876\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0232 - accuracy: 0.8889\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0228 - accuracy: 0.8904\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0224 - accuracy: 0.8914\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0220 - accuracy: 0.8924\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0217 - accuracy: 0.8936\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0214 - accuracy: 0.8950\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0211 - accuracy: 0.8961\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0208 - accuracy: 0.8971\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0206 - accuracy: 0.8980\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0203 - accuracy: 0.8989\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0201 - accuracy: 0.9000\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.9012\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0196 - accuracy: 0.9018\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0194 - accuracy: 0.9025\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0192 - accuracy: 0.9029\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0190 - accuracy: 0.9037\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0189 - accuracy: 0.9043\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0187 - accuracy: 0.9050\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0185 - accuracy: 0.9058\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0183 - accuracy: 0.9065\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0182 - accuracy: 0.9072\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0180 - accuracy: 0.9078\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0179 - accuracy: 0.9084\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0177 - accuracy: 0.9091\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0176 - accuracy: 0.9096\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0174 - accuracy: 0.9100\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0173 - accuracy: 0.9106\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0172 - accuracy: 0.9112\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0171 - accuracy: 0.9117\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0169 - accuracy: 0.9122\n",
      "Test loss: 0.0160282701253891\n",
      "Test accuracy: 0.9186000227928162\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# MNIST Dataset Preparation #\n",
    "#############################\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train_vec), (x_test, y_test_vec) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train_vec, 10, dtype='float64')\n",
    "y_test = tf.keras.utils.to_categorical(y_test_vec, 10, dtype='float64')\n",
    "\n",
    "##################\n",
    "# Training phase #\n",
    "##################\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(H, activation='relu', input_dim=784))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.compile(optimizer=SGD(learning_rate=A), loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=E, verbose=1)\n",
    "\n",
    "##################\n",
    "# Testing phase  #\n",
    "##################\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
